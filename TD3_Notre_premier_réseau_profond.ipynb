{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juatc83/publicCodes/blob/main/TD3_Notre_premier_r%C3%A9seau_profond.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWGMt0fKFlqR"
      },
      "source": [
        "PyTorch a une librairie de modèles et outils pour la vision : TorchVision https://pytorch.org/docs/stable/torchvision/index.html (téléchargeable ici : https://github.com/pytorch/vision, mais vous n'avez pas besoin de le télécharger pour ce TD car il est déjà installé dans Colab).\n",
        "\n",
        "Parmi les modèles disponibles (https://pytorch.org/docs/stable/torchvision/models.html), nous allons utiliser AlexNet que nous avons découvert lors du dernier cours. TorchVision implémente une version d'AlexNet et a même une version du réseau déjà entrainée sur ImageNet. Nous allons charger ce modèle :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg4fLTAzFVWp"
      },
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "\n",
        "model = models.alexnet(pretrained=True, progress=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9btjAaFH1Uf"
      },
      "source": [
        "**Exercice  0**\n",
        "\n",
        "Vérifiez que l'architecture d'AlexNet est bien implémentée :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlytE4GwHdJM"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGtEo1l3H8t1"
      },
      "source": [
        "**Exercice 1**\n",
        "\n",
        "*Chargement d'une image*\n",
        "\n",
        "Nous allons tout d'abord nous exercer à utiliser un modèle déjà entrainé.\n",
        "\n",
        "Vous trouverez une image de poisson clown sur Moodle. Téléchargez là et charger là dans Colab en utilisant le bouton 'importer' de l'onglet 'Fichiers' dans le volet de gauche de cette page.\n",
        "\n",
        "TorchVision utilise Pillow par défaut pour manipuler les images. Nous allons donc charger l'image à l'aide de Pillow :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63Xk7grEPFgw"
      },
      "source": [
        "from PIL import Image\n",
        "img = Image.open(\"clown_fish.jpg\")\n",
        "\n",
        "from IPython.display import display\n",
        "display(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axJbRzZ7P8ZK"
      },
      "source": [
        "*Préparation de l'image*\n",
        "\n",
        "Puisque le modèle AlexNet a été pré-entrainé sur ImageNet, il s'attend à recevoir des images d'une certaine taille, et ayant été normalisées de la même manière que les images d'entrainement (voir les explications du pré-entrainement sur https://pytorch.org/docs/stable/torchvision/models.html).\n",
        "\n",
        "TorchVision a justement un module de préparation d'image appelé `transforms` (https://pytorch.org/docs/stable/torchvision/transforms.html) que nous allons pouvoir utiliser pour rendre notre image adéquate.\n",
        "\n",
        "Vérifiez sur https://pytorch.org/docs/stable/torchvision/transforms.html#transforms-on-pil-image-and-torch-tensor ce que font les différentes opérations de préparation implémentées ci-dessous."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mqbSC2DQxTK"
      },
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        " transforms.Resize(256),             \n",
        " transforms.CenterCrop(224),         \n",
        " transforms.ToTensor(),              \n",
        " transforms.Normalize(               \n",
        " mean=[0.485, 0.456, 0.406],         \n",
        " std=[0.229, 0.224, 0.225]           \n",
        " )])\n",
        "\n",
        "# application de la transformation à notre image\n",
        "img_t = preprocess(img)\n",
        "\n",
        "# une image Tensor peut être visualisée avec Matplotlib\n",
        "# en permutant les dimension (C, H, W) -> (H, W, C)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(  img_t.permute(1, 2, 0)  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MF27k71zS0ms"
      },
      "source": [
        "Comme le modèle AlexNet s'attend à recevoir un batch d'images, on crée un batch d'une seule image :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vuavIqsS7tW"
      },
      "source": [
        "batch_t = torch.unsqueeze(img_t, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o3AVowNTGD9"
      },
      "source": [
        "*Evaluation de l'image par le modèle*\n",
        "\n",
        "L'image est maintenant prête à être donnée au modèle pour estimer sa classification :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3Dw8ondTVw0"
      },
      "source": [
        "# bascule du modèle en mode 'évaluation', c.a.d. 'test'\n",
        "model.eval()\n",
        "\n",
        "# déplace le modèle et le batch dans le GPU\n",
        "if torch.cuda.is_available():\n",
        "    batch_t = batch_t.to('cuda')\n",
        "    model.to('cuda')\n",
        "\n",
        "# inférence\n",
        "with torch.no_grad():\n",
        "  out = model(batch_t)\n",
        "\n",
        "print(out[0].shape)\n",
        "\n",
        "# normalisation des scores par softmax pour avoir une pseudo-probabilité\n",
        "scores = torch.nn.functional.softmax(out[0], dim=0)\n",
        "print(scores.sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpKcTcPBTsAP"
      },
      "source": [
        "Quelle est la taille de la sortie du réseau ? Que cela veut-il dire à votre avis ? (scrollez pour continuer, mais attention, spoiler !)\n",
        "\n",
        "![](http://eurinfac.com/wp-content/uploads/2015/02/image-blanche.png)\n",
        "\n",
        "![](http://eurinfac.com/wp-content/uploads/2015/02/image-blanche.png)\n",
        "\n",
        "![](http://eurinfac.com/wp-content/uploads/2015/02/image-blanche.png)\n",
        "\n",
        "![](http://eurinfac.com/wp-content/uploads/2015/02/image-blanche.png)\n",
        "\n",
        "Pour interpréter la réponse du réseau, nous devons au préalable charger les noms des classes correspondants aux éléments du vecteur de sortie :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_4C85i7XRCC"
      },
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "LABELS_URL = 'https://s3.amazonaws.com/mlpipes/pytorch-quick-start/labels.json'\n",
        "labels = {int(key):value for (key, value)\n",
        " in requests.get(LABELS_URL).json().items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df4TZGq4syOd"
      },
      "source": [
        "En vous aidant des fonctions `torch.max` et `torch.sort`, déterminez la classe prédite par le modèle, et les 5 classes les plus probables. Affichez aussi leurs scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRVSNdegtJli"
      },
      "source": [
        "## à compléter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCZ9Fu9wtKfb"
      },
      "source": [
        "Solution plus bas.\n",
        "\n",
        "![](http://eurinfac.com/wp-content/uploads/2015/02/image-blanche.png)\n",
        "\n",
        "![](http://eurinfac.com/wp-content/uploads/2015/02/image-blanche.png)\n",
        "\n",
        "![](http://eurinfac.com/wp-content/uploads/2015/02/image-blanche.png)\n",
        "\n",
        "![](http://eurinfac.com/wp-content/uploads/2015/02/image-blanche.png)\n",
        "\n",
        "Solution :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlbBUtEutQ7Y"
      },
      "source": [
        "# classe avec le plus haut score\n",
        "score, index = torch.max(out, 1)\n",
        "print(index.item(), labels[index.item()], score.item())\n",
        "\n",
        "# 5 meilleures classes\n",
        "scores, indices = torch.sort(out, descending=True)\n",
        "top5 = [(ind.item(), labels[ind.item()], sc.item()) for sc, ind in zip(scores[0][:5], indices[0][:5])]\n",
        "print(top5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNUpqosrqFIN"
      },
      "source": [
        "Vous pouvez si vous le souhaitez essayer le modèle avec d'autres images à charger sur Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKgWSoqmPKUg"
      },
      "source": [
        "**Exercice 2**\n",
        "\n",
        "Nous allons maintenant entrainer notre propre modèle. Imaginons que nos ressources sont limitées, aussi bien en nombre d'images dans notre dataset qu'en temps de calcul. Il existe une solution très populaire à ce problème : le **pré-entrainement**.\n",
        "\n",
        "Il est possible de charger un modèle pré-entrainé sur un grand dataset, puis de continuer son entrainement pour le spécialiser sur nos données et notre tâche. On appelle cela le **fine-tuning**.\n",
        "\n",
        "Pendant le fine-tuning, les paramètres des premières couches bas-niveau d'un CNN n'auront pas besoin d'être réappris de manière significative car les filtres bas-niveaux sont probablement aussi bons pour nos images qu'ils l'étaient pour celles du dataset de pré-entrainement. Il faudra donc surtout ré-entrainer les paramètres des couches haut-niveau, ce qui demande moins d'itérations. De plus, ces couches étant initialisées avec des valeurs pas franchement aléatoires et probablement pas si bêtes que ça, nous aurons besoin d'encore moins d'itérations. Autre avantage du fine-tuning : le modèle a déjà appris à traiter une certaine variété de données, ce qui réduit les problèmes liés à la petite taille de notre dataset.\n",
        "\n",
        "Dans notre cas, nous allons utiliser le modèle AlexNet pré-entrainé sur ImageNet, et nous le spécialiserons sur la classification des chiffres de MNIST.\n",
        "\n",
        "Nous allons supposer que les descripteurs appris pour les images de ImageNet feront bien l'affaire pour les images de MNIST. Nous allons donc simplifier au maximum le fine-tuning pour ne changer que la classification d'AlexNet, en conservant donc l'extraction de features telle qu'elle est maintenant. En fait, nous n'allons même changer que la dernière couche de classification, celle qui renvoie les scores des classes. Cette version extrême du fine-tuning s'appelle **feature extraction** car nous utilisons les features du CNN et nous réapprenons simplement un nouveau classifier qui les utilise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TokOv4nPnSUk"
      },
      "source": [
        "*Modification de l'architecture du réseau*\n",
        "\n",
        "Nous avons examiné la structure d'AlexNet en début de ce TD. Nous avons vu que la dernière couche du réseau est la 6ème couche de classification :\n",
        "`(6): Linear(in_features=4096, out_features=1000, bias=True)`\n",
        "\n",
        "Comme MNIST a 10 classes et non 1000, il faut donc remplacer cette couche par une couche avec 10 sorties. **Complétez le code ci-dessous.**\n",
        "\n",
        "Autre modification nécessaire : il faut dire à PyTorch de ne pas appliquer l'autograd aux couches qui ne doivent pas être modifiées pendant le fine-tuning (puisque nous avons décidé de ne modifier que la dernière couche).\n",
        "Remarque : par défaut les couches nouvellement ajoutées ont `requires_grad = True`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqfPKmLHooGM"
      },
      "source": [
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "# modification de la dernière couche du réseau (à compléter)\n",
        "model.classifier[6] = ### à compléter\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sx8EptxkojZp"
      },
      "source": [
        "*Chargement du dataset*\n",
        "\n",
        "TorchVision contient des fonctions d'aide pour télécharger les datasets les plus populaires (https://pytorch.org/docs/stable/torchvision/datasets.html). Nous pouvons donc facilement télécharger MNIST.\n",
        "\n",
        "Puisque nous ne changeons pas les couches d'extraction de features du réseau, nous devons nous assurer que les images respectent la taille et la normalisation des images attendues par le réseau. Cela peut être fait automatiquement en passant un objet `transforms` de préparation des images à la fonction de chargement du dataset.\n",
        "\n",
        "De plus, lors de l'entrainement, nous pouvons augmenter artificiellement la taille de notre set d'entrainement en appliquant des transformations de manière aléatoire à nos images. Cela s'appelle l'**augmentation**, et peut être aussi réalisé par l'objet `transforms`. **Examinez les transformations disponibles** (https://pytorch.org/docs/stable/torchvision/transforms.html#transforms-on-pil-image-and-torch-tensor) **et choisissez une ou des transformations applicables aux images de MNIST.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dhEb6d7jBqE"
      },
      "source": [
        "preprocess_train = transforms.Compose([\n",
        " transforms.Grayscale(num_output_channels=3), \n",
        " transforms.Resize(224), \n",
        " ### à compléter\n",
        " transforms.ToTensor(),              \n",
        " transforms.Normalize(               \n",
        " mean=[0.485, 0.456, 0.406],         \n",
        " std=[0.229, 0.224, 0.225]           \n",
        " )])\n",
        "\n",
        "preprocess_test = transforms.Compose([\n",
        " transforms.Grayscale(num_output_channels=3), \n",
        " transforms.Resize(224),         \n",
        " transforms.ToTensor(),              \n",
        " transforms.Normalize(               \n",
        " mean=[0.485, 0.456, 0.406],         \n",
        " std=[0.229, 0.224, 0.225]           \n",
        " )])\n",
        "\n",
        "from torchvision import datasets\n",
        "mnist_train = datasets.MNIST('./MNIST/', train=True, download=True,\n",
        "                       transform=preprocess_train)\n",
        "mnist_test = datasets.MNIST('./MNIST/', train=False, download=True,\n",
        "                       transform=preprocess_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOy5nLlG-55J"
      },
      "source": [
        "PyTorch a un objet `DataLoader` qui se charge de transférer les données par batch au modèle, avec shuffling aléatoire :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg7Xs0KxBJbU"
      },
      "source": [
        "batch_size = 1000\n",
        "loader_train = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "loader_test = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=True, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQeBFgeQCWAK"
      },
      "source": [
        "*Création de l'optimizer*\n",
        "\n",
        "En suivant l'exemple du TD2, créer un optimizer pour votre modèle. Rappelez-vous que cet optimizer ne doit mettre à jour que les paramètres de la dernière couche du AlexNet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikM7cNY5Fex9"
      },
      "source": [
        "# liste des paramètres à mettre à jour\n",
        "params_to_update = []\n",
        "### à compléter\n",
        "\n",
        "learning_rate = 0.001\n",
        "momentum = 0.9\n",
        "### à compléter : création de l'optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Xgj2AuHFkIX"
      },
      "source": [
        "Solution plus bas\n",
        "\n",
        "![](http://eurinfac.com/wp-content/uploads/2015/02/image-blanche.png)\n",
        "\n",
        "![](http://eurinfac.com/wp-content/uploads/2015/02/image-blanche.png)\n",
        "\n",
        "![](http://eurinfac.com/wp-content/uploads/2015/02/image-blanche.png)\n",
        "\n",
        "![](http://eurinfac.com/wp-content/uploads/2015/02/image-blanche.png)\n",
        "\n",
        "Solution :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4Mh-o2TCa-g"
      },
      "source": [
        "# liste des paramètres à mettre à jour\n",
        "params_to_update = []\n",
        "for param in model.parameters():\n",
        "  if param.requires_grad == True:\n",
        "    params_to_update.append(param)\n",
        "\n",
        "### création de l'optimizer\n",
        "learning_rate = 0.001\n",
        "momentum = 0.9\n",
        "optimizer = torch.optim.SGD(params_to_update, lr=learning_rate, momentum=momentum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lq4SKj4dGD_a"
      },
      "source": [
        "*Entrainement du réseau*\n",
        "\n",
        "Nous allons procéder à l'entrainement du réseau avec une fonction de coût adaptée à la classification. Essayons par exemple `torch.nn.CrossEntropyLoss`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5gDKW4GGxJx"
      },
      "source": [
        "loss_function = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dF9sOLrhG5nn"
      },
      "source": [
        "Entrainons la dernière couche du réseau pendant une époque :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcfNdstCJif8"
      },
      "source": [
        "model.train() # on se remet en mode 'entrainement'\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model.to('cuda')\n",
        "\n",
        "for epoch in range(1):  # loop over the dataset multiple times\n",
        "\n",
        "    for i, data in enumerate(loader_train, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "          inputs = inputs.to('cuda')\n",
        "          labels = labels.to('cuda')\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_function(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        print('[%d, %5d] loss: %.3f' %\n",
        "              (epoch + 1, i + 1, loss.item()))\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYdYams5rLJ2"
      },
      "source": [
        "Testons maintenant notre nouveau réseau sur les données de test :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlD8Tdu6rPGP"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "average_loss = 0.0\n",
        "\n",
        "for i, data in enumerate(loader_test, 0):\n",
        "  # get the inputs; data is a list of [inputs, labels]\n",
        "  inputs, labels = data\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "    inputs = inputs.to('cuda')\n",
        "    labels = labels.to('cuda')\n",
        "\n",
        "  # forward\n",
        "  outputs = model(inputs)\n",
        "  loss = loss_function(outputs, labels)\n",
        "\n",
        "  average_loss += loss.item()\n",
        "  \n",
        "  # print statistics\n",
        "  print('%5d loss: %.3f' %\n",
        "    (i + 1, loss.item()))\n",
        "\n",
        "print('Finished testing. Average loss: %.3f' %\n",
        "      (average_loss/(i+1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIrwAjc1wWTk"
      },
      "source": [
        "Voyons aussi ce que fait le réseau sur quelques images prises au hasard :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zjhSN8awZqd"
      },
      "source": [
        "inputs, classes = next(iter(loader_test))\n",
        "\n",
        "plt.imshow(  inputs[0].permute(1, 2, 0)  )\n",
        "print('classe prédite %d : ' %\n",
        "      classes[0].item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SYuGyRBzxIi"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    inputs = inputs.to('cuda')\n",
        "    labels = labels.to('cuda')\n",
        "\n",
        "batch_t = torch.unsqueeze(inputs[0], 0)\n",
        "output = model(batch_t)\n",
        "\n",
        "score, index = torch.max(output, 1)\n",
        "print(index.item(), score.item())\n",
        "\n",
        "scores, indices = torch.sort(output, descending=True)\n",
        "top3 = [(ind.item(), sc.item()) for sc, ind in zip(scores[0][:3], indices[0][:3])]\n",
        "print(top3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3of-GP9nFt5"
      },
      "source": [
        "Félicitations, vous avez entrainé votre premier réseau de neurones ! Dans le prochain TD nous examinerons son fonctionnement en détail grâce à la visualisation."
      ]
    }
  ]
}